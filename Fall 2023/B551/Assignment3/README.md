# fraramir-nhaldert-pcoen-a2
## Part 1: Raichu
 - We treated this problem as a simplified version of chess. First, we began by defining all the possible moves for each piece. This was probably one of the most time-consuming aspects of this problem as there are a lot of small things to take care of while defining the moves. Although not highly complex, defining all moves and making sure they were working properly was quite some work. We will explain how our program works below.

 - As mentioned above, we first defined all moves. Then, we assigned different "rewards" to different moves. For a regular move in which no raichu was created and no piece was eaten, we added no reward (a reward of 0 that is). For a move that ate a pichu we added a reward of 1, and for a move that ate a pikachu or raichu we added a reward of 2 and 3, respectively. Then, we added a reward of 4 to creating raichu. In our opinion, this is typically the best possible move because of how "powerful" the raichu is as a piece. Continued in next bullet.

 - Nonetheless, we realized that some of the cases above for which we had different rewards could happen simultaneously. That is, one of our player's piece could jump over an opponent's piece (eating it) and reach the end of the board, all in a single move. If that happens, a raichu will be created. Hence, combining the rewards stated in the previous bullet, we added a reward of 5 for a move that ate a pipchu and created raichu, and we added a reward of 6 for a move that ate a pikachu and created a raichu. Notice that eating a raichu and creating a raichu on the same move is not possible, as a raichu can only be eaten by another raichu. The reward for eating a raichu and possibly reaching the end of the board remains as 3 (from above). Continued in next bullet.

 - As for implementation, we used a priority queue with negated rewards. That way the highest reward had the highest priority, and it would be popped from the priority queue first. Notice, however, that we print all possible moves first (due to time constraints), and then print the one with the highest priority once more. So the best possible move will be printed twice, the second time will be the last move printed so the autograder will ideally consider that one.

 - Notice that we were choosing the best move possible based only on ourselves. In other words, we were not considering any possible move from our opponents. Hence, we added a modification to our program, which now work as a 2-step process. At first we consider a possible for us, then for each of that possible move we calculate the impact of that move by simply calculating all the possible move of opponent pieces for our move. We consider the fact that for one of our move, how it is impacting our chances of winning, in simpler terms do we have more pieces then opponents after making this move. Then we are applying this impact score on top of our already developed move score. We do this for all the possible move for us and find the move that is most beneficial for that instance. This way we are considering 1 move ahead always when choosing a move. Also, for each of our moves we are emphasizing going forward for Pikachus. So, we added an extra 0.5 score to the moves of pikachu if a forward move is made. This strategy was implemented to follow an attack-based approach and possibly creating raichu in the process. Finally to ensure we do not go past the given timer, we are printing each of the possible move for a given board for player and then finally printing the best move.
<!-- In the first step (described above), we add all possible moves to a priority queue. Then, during the second step, we pop all moves with equal priority from the queue, and consider all possible opponent moves in each of the boards that we popped from the queue. That way we can break ties between all moves with equal highest priority by picking the board that leads to a board in which our opponent will have a lower reward (similar to the rationale behind mini-max pruning). This way we are looking one extra move ahead. Also, notice that this time we do not print our opponent moves as those would be invalid moves. Hence, we wait to compute the best possible board. If the timer ends and we were still computing opponent moves, then that is fine as the last print statement corresponded to the move with the highest priority from our player. Lastly, notice that ties in opponent moves are broken arbitrarily. -->


## Part 2: Truth be Told
 - As the assignment said, we formulated the problem as a maximum likelihood estimate using a smoothed bayesian classifier. Classification is done by checking which class has the higher log probability value. (This was a very similar problem to one give on an assignment in CSCI-B555)
   - Initially this was framed as (word given class) / (number of word tokens from a class). We look at the log probability of this sum from a sentence to avoid underflow errors with minute probabilities.
   - This was then modified to include a smoothing parameter to attempt to get superior performance to the normal model. This is framed as (word given class + smoothing parameter) / (number of word tokens from a class + vocabulary size). This helps to ensure we always classify, even when no words match anything from our training set.
   - Additionally, this causes it to use a MAP estimate for the values predicted. This increases accuracy a bit, up to 88% from our testing. (The original correctness without MAP estimates was in the upper 60s to low 70s percentage range).
   - There is some data normalization also done, such as making all words lowercase and removing punctuation. We also have a threshold to define what words to cut out of the dataset if they only occur a handful of times. This allows words with less than a handful of occurrences to be ignored. Lastly, we added a stop word check from a list of known stop words from English. This removes those words from consideration as they do not provide semantic value and tend to confuse classifiers.
 - Overall, this should have superior performance to a normal classifier model, but it is sensitive to the hyperparameters (smoothing_constant and remove_threshold).
